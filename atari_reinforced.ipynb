{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing atari games like a pro\n",
    "\n",
    "Ever got frustaded for your lack of coordination when it comes to pressing button and breathing at the same time?\n",
    "\n",
    "(image of discordinated human) YES!!!!\n",
    "\n",
    "So this article is for you! With the help of deep learning lets help our laziness to make the computer play a game for us while we focus on breathing watching bogo cat play its songs.\n",
    "\n",
    "(image of bongo cat)\n",
    "\n",
    "## Requirement for this article\n",
    "\n",
    "This time we will not go through all the basics of neuro networks. So make sure that you know at least some basics of deep learning, convolution layers and quantum physics.\n",
    "\n",
    "Also we will be using **pytorch** for runing and trainig our models. So knowing a bit about **pytorch** also helps.\n",
    "\n",
    "## Deep reinforcement learning?\n",
    "\n",
    "You probably head about the most common types of machine learning: supervised and unsupervised. There is a third category of learning named reinforcement learning. So how does these three brothers differs from each other?\n",
    "\n",
    "#### Supervised learning\n",
    "\n",
    "This is the most common kind of machine learning. In this type the model has access to both the question (input) and the answer (output). It then can make a guess about the input and calculate how much it missed from the real output. Then use this difference to update its weights.\n",
    "\n",
    "This type of learning is really good too use in object recognition.\n",
    "\n",
    "(image of classifier)\n",
    "\n",
    "#### Unsupervised learning\n",
    "\n",
    "In this case the model has no access to the answers to the question. E.g it only has the input data but not the output. So the machine will try to model the input by understanding the differences and similarities between them. \n",
    "\n",
    "This type of learning can be used for clustering or even audio/video synthesis.\n",
    "\n",
    "(image of GAN)\n",
    "\n",
    "#### Reinforcement learning\n",
    "\n",
    "Now this less used type of learning has some peculiarities. First it can interact with the environment by a set of actions and then observes how its actions changes the environment (also called state).\n",
    "\n",
    "This type of AI has the objective to maximize the rewards it gets from the environment. Using games as an exemple, the score can be a reward, so the machine will try to learn what kind of actions are the best to use in each possible state so that it can achieve the maximum amount of rewards.\n",
    "\n",
    "Like in this article, this type of learning can be used to play games. But on a more useful note, it can be used to teach robots to move on a most efficient way or even teach self-driving cars to drive as safe as possible.\n",
    "\n",
    "(image of robots high fiveing each other)\n",
    "\n",
    "##### Some terms\n",
    "\n",
    "Reinforcement lerning has some special terms that are not used by the other forms of learning:\n",
    "- **Agent**: The individual who interacts with the world. For example, the robot who can brag stuff on a table or the character on a game.\n",
    "- **Action**: How the agent interact with the envirounment. For example, the robot has the possible actions of moving left, right, opening and closing its claw.\n",
    "- **State**: How the envirounment looks like. Most of the time the agent has not access to the all possible states at once.\n",
    "- **Reward**: It can come as a positive reward or as a negative reward (also called punishiment). The rules for how the reward is given depends on the envirounment.\n",
    "\n",
    "### Where the \"deep\" comes from\n",
    "\n",
    "Like with deep neural networks for supervised learning, when we say deep reinforcement learning, what we mean is that we will use a deep neural network to model what are the best actions to choose depending on the state the evironment is now. \n",
    "\n",
    "...and it sounds cooler.\n",
    "\n",
    "\n",
    "## OpenAI gym\n",
    "\n",
    "OpenAI is a non-profit AI research company that provide us with a bunch of cool tool to train reiforcement leaning models. These are normaly small games with an easy interface for rendering and action input. \n",
    "We could use an emulator to be able to run any game we can want, however in this article we want to focus on the model training part so we will be using the OpenAI gym libraries to create and interact with our games.\n",
    "\n",
    "Installing the library is pretty straighforward. Just run **pip install gym** or **pip install --user gym** to keep the library local, and if you are using Gentoo, you need to add that **--user**\n",
    "\n",
    "Here lets try to import and play our game with random actions for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Skiing-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we have the environment loaded. We can now check what is sent to us from the envirounment as output and what actions we can give to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this envirounment allow the agent to do 3 diffenrent discrete actions: 0,1 and 2. This implies that our network will need 3 neurons so we can model these actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAD8CAYAAAA18TUwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAC+RJREFUeJzt3V2IXPUZx/Hvr7Z6YQVNl9j40hpthOqNlZAGLOJNfQmF1QtDBJtULfHCQAMtNCq0Um+saH3BIkQqxtqqgdYapLZqKNgbX6JoTLTRrQaNCVm2EWsRtOrTi3PGTjYzO2dn5uyZffL7wDBnzpyZ82Tz2zP/Of/ZeRQRmGX0haYLMKuLw21pOdyWlsNtaTnclpbDbWnVFm5JF0raJWlC0oa69mPWjeo4zy3pCOB14LvAHuB54LKIeHXoOzProq4j9zJgIiLejIiPgYeA8Zr2ZdbRF2t63hOBd9pu7wG+3W1jSZ4mtcoiQlW2qyvcnXZ+UIAlrQXW1rR/s9rCvQc4ue32ScDe9g0iYiOwEXzktnrUNeZ+HlgiabGkI4FVwJaa9mXWUS1H7oj4RNI64K/AEcC9EbGzjn2ZdVPLqcBZF+Fhic1C1TeUnqG0tBxuS8vhtrQcbkvL4ba0HG5Ly+G2tBxuS8vhtrQcbkvL4ba0HG5Ly+G2tBxuS8vhtrQcbkvL4ba0HG5Lq66/fh+aqamppkuwBoyNjQ38HD5yW1oOt6U18sOSbKa/3LYPu2a6z2bPR+45NjU19fkFOge62302Ow63peVhyRzz0GPuONwNcKDnhsPdgKpvKv1LMBiHe47NFFiHebj8htLScrgtLQ9LatDrjEi3++t63OHKR+6adJqMGRsb+3y522RNt/X9Pu5w5nDPIR9R55bDPYd8RJ1bDvc84F+K/gz0hlLSbuAD4FPgk4hYKmkB8DBwCrAbWBkR7w1W5vzTaTKmfUzcbbKm2/qpqam+Hnc4G6jhUxnupREx1bbuZuBARNwkaQNwXET8tMfzdC3C/1GHp5lerZps+DQObCqXNwEX17APs54GDXcAT0h6oWx3DXB8ROwDKK8XdnqgpLWStknaNmANZh0NOolzTkTslbQQeFLSP6o+0O2xrW4DHbkjYm95PQk8AiwD9ktaBFBeTw5apFk/+g63pKMlHdNaBs4HdlD0eF9TbrYGeHTQIs36Mciw5HjgEUmt5/l9RPxF0vPAZklXAW8Dlw5eptnsjXzvd58KPDyN6qlAs5HgcFtaDrel5XBbWg63peVwW1oOt6XlcFtaDveIm1y/nsn165suY15yuEeYQz0Yh3tEOdiDc7hHUKdgO+yz53CPqIW33950CfOew21pOdwjysOQwTncI6h9SNJa9jBl9hzuEbbw9tt9BB+Awz3CHOzBONzzgIck/XG4R5hDPRiH29JyuC0th9vS8veW2Ejy95aYzcDhtrQcbkvL4ba0HG5Ly+G2tBxuS8vhtrQcbkvL4ba0eoZb0r2SJiXtaFu3QNKTkt4or48r10vSnZImJG2XdHadxZvNpMqR+z7gwmnrNgBbI2IJsLW8DXARsKS8rAXuHk6ZZrPXM9wR8TRwYNrqbi2wx4H7o/AMcGyrJ6XZXOt3zN2tBfaJwDtt2+0p15nNuUHbY0/X6aOIHT/OWvaKX9vpPrNh6PfI3a0F9h7g5LbtTgL2dnqCiNgYEUsjYmmfNZjNqN9wd2uBvQVYXZ41WQ683xq+mM21nsMSSQ8C5wFjkvYAPwduonML7D8DK4AJ4EPgihpqNqvEf2ZmI8l/ZmY2A4fb0nK4LS2H29JyuC0th9vScrgtLYfb0nK4LS2H29JyuC0th9vScrgtLYfb0nK4LS2H29JyuC0th9vScrgtLYfb0nK4LS2H29JyuC0th9vScrgtLYfb0nK4LS2H29JyuC0th9vScrgtLYfb0nK4LS2H20bOL/60cijP43BbWv32fr9B0ruSXiovK9ruu7bs/b5L0gV1FW7WS5Umq/cBdwH3T1t/W0Tc0r5C0hnAKuBM4ATgKUmnR8SnQ6jVkhvWcKSl397v3YwDD0XERxHxFkXLvmUD1GfWt0HG3OskbS+HLceV6yr3fpe0VtI2SdsGqMGsq37DfTdwGnAWsA+4tVxfufe722Nb3aqMuQ8REftby5LuAR4rb1bu/W423c8u3vz58p0/7N5ktaq+jtySFrXdvARonUnZAqySdJSkxcAS4LnBSrTDzbDeWPZsj93e+x3YT9H7/TyKIUkAu4GrI2Jfuf31wJXAJ8D6iHi8ZxFuj23TDKM9tnu/20hy73ezGTjclpbDbWk53JaWw21pOdyWlsNtaTncllZfny2xwUxOTh50e+HChQ1VkpvDXbPpQZ5pG4d8uDwsqcnk5GSlYE9/jA2Pw21peVhSk9YQo8rR2MORejjcNXNwm+NhiaXlcFtaDrel5XBbWg63peVwW1oOt6XlcFtaDncPKy+fYOXlE2n3l5nDPYO5DplDPVwOdxcO9vzncHex+YFvpN7f4cDhtrQc7hn46D2/Odw9OODzl8NtaTnclpbDbWk53JaWw21pVemJczJF9+CvAp8BGyPiDkkLgIeBUyj64qyMiPckCbgDWAF8CPwgIl7ssQ+3DbGDzFXbkE+AH0fEN4HlwDVlG+wNwNaIWAJsLW8DXETRxWwJsJaiZ6XZnKvSHntf68gbER8Ar1F0BR4HNpWbbQIuLpfHgfuj8Axw7LTWfmZzYlZjbkmnAN8CngWOb7XnK69bX9BRuUW2WZ0qfymPpC8Df6DoLfnvYmjdedMO6w4ZU0taSzFsMatFpSO3pC9RBPt3EfHHcvX+1nCjvG59b1ilFtnu/Z7X5Y9d3nQJQIVwl2c/fgO8FhG/artrC7CmXF4DPNq2frUKy4H3W8MXOzw88L0Hmi4BqHYq8DvA34FXKE4FAlxHMe7eDHwNeBu4NCIOlL8MdwEXUpwKvCIitvXYh08F2kHcHtvScntssxk43JaWw21pOdyWlsNtaTnclpbDbWk53JaWw21pOdyWlsNtaTnclpbDbWk53JaWw21pOdyWlsNtaTnclpbDbWk53JaWw21pOdyWlsNtaTnclpbDbWk53JaWw21pOdyWlsNtaTnclpbDbWk53JaWw21pOdyWlsNtaVXpZnaypL9Jek3STkk/KtffIOldSS+VlxVtj7lW0oSkXZIuqPMfYNZNlSarrd7vL0o6BnhB0pPlfbdFxC3tG5d94VcBZwInAE9JOj0iPh1m4Wa9DNL7vZtx4KGI+Cgi3gImgGXDKNZsNiq3x4ZDer+fA6yTtBrYRnF0f48i+M+0Paxj7/dp7bH/A/wLOKQv30wt2xo0RodaR9h8qrdXrV+v+kSD9H6/G7iRoq/7jcCtwJVU7P0eERuBjW3Pv22+tMqeT7XC/Kp3mLX23fs9IvZHxKcR8RlwD/8felTq/W5Wt757v0ta1LbZJcCOcnkLsErSUZIWA0uA54ZXslk1VYYl5wDfB16R9FK57jrgMklnUQw5dgNXA0TETkmbgVcpzrRcU/FMycbem4yM+VQrzK96h1brSPR+N6uDZygtrcbDLenCciZzQtKGpuvpRNJuSa+UM7HbynULJD0p6Y3y+riGartX0qSkHW3rOtamwp3lz3q7pLNHpN56ZrsjorELcATwT+BU4EjgZeCMJmvqUuduYGzaupuBDeXyBuCXDdV2LnA2sKNXbcAK4HGK07XLgWdHpN4bgJ902PaMMhNHAYvLrBxRdV9NH7mXARMR8WZEfAw8RDHDOR+MA5vK5U3AxU0UERFPAwemre5W2zhwfxSeAY6ddtardl3q7Wag2e6mw30i8E7b7Y6zmSMggCckvVDOrAIcHxH7oPiIArCwseoO1a22Uf55ryuHSve2DfEGqrfpcFeazRwB50TE2cBFwDWSzm26oD6N6s/7buA04CxgH8VsNwxYb9PhnhezmRGxt7yeBB6heGnc33pJL68nm6vwEN1qG8mfd9Q02910uJ8HlkhaLOlIio/Kbmm4poNIOrr8qC+SjgbOp5iN3QKsKTdbAzzaTIUddattC7C6PGuyHHi/NXxpUm2z3U28w5/2jngF8DrFO+Hrm66nQ32nUrxjfxnY2aoR+AqwFXijvF7QUH0PUryU/5fiSHdVt9ooXuZ/Xf6sXwGWjki9vy3r2V4GelHb9teX9e4CLprNvjxDaWk1PSwxq43DbWk53JaWw21pOdyWlsNtaTnclpbDbWn9D2v2XBjlZVTQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = env.reset()\n",
    "#img = env.observation_space.sample(0)\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see an example of how the game looks like. Every state is a (250,160,3) image where the last dimension is the RGB channel of the image.\n",
    "\n",
    "So, how about we try to run once at random and check how well we performed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "img_list = []\n",
    "reward_list = []\n",
    "for _ in range(1000):\n",
    "    action = np.random.randint(0,3)\n",
    "    img, reward, done, _ = env.step(action)\n",
    "    img_list.append(img)\n",
    "    reward_list.append(reward)\n",
    "    if(done):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
